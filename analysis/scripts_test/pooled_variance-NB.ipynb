{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "organizational-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extreme-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(2,0.1, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spoken-producer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010035225393973375"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_var = a.var()\n",
    "true_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "industrial-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.reshape(20,500)\n",
    "b_mean = b.mean(axis=-1)\n",
    "b_var  = b.var(axis=-1)\n",
    "n = np.full((20),500)\n",
    "pooled_mean = np.average(b_mean, weights = n, axis=0)\n",
    "pooled_var  = np.average(b_var,  weights = n, axis=0) + np.average((b_mean-pooled_mean)**2, weights = n, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assisted-workshop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.998557814622302"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "loose-composer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010035225393973373"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "secret-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a.reshape(200,50)\n",
    "c_mean = c.mean(axis=-1)\n",
    "c_var  = c.var(axis=-1)\n",
    "n = np.full((200),50)\n",
    "pooled_mean = np.average(c_mean, weights = n, axis=0)\n",
    "pooled_var  = np.average(c_var,  weights = n, axis=0) + np.average((c_mean-pooled_mean)**2, weights = n, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intellectual-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9985578146223015"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effective-enlargement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010035225393973375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-lesbian",
   "metadata": {},
   "source": [
    "We see that the pooled variances are identical. Thus it does not matter if we group a into 20 groups of 500 or 200 groups of 50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-found",
   "metadata": {},
   "source": [
    "to test the above in practice, the code below splits the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def func(self, log_or_lin, save=False):\n",
    "        \n",
    "        n_points=20 # number of points to plot\n",
    "        self.log_or_lin = log_or_lin\n",
    "        if log_or_lin.startswith('log'):\n",
    "            self.mjd_edges = np.logspace(0, 4.37247, n_points+1) # TODO add max t into argument\n",
    "        elif log_or_lin.startswith('lin'):\n",
    "            self.mjd_edges = np.linspace(0, 23576, n_points+1)\n",
    "            \n",
    "        self.mjd_centres = (self.mjd_edges[:-1] + self.mjd_edges[1:])/2\n",
    "        \n",
    "        if __name__ == '__main__':\n",
    "            n_cores = 4\n",
    "            p = Pool(n_cores)\n",
    "            names = ['n', 'mean weighted a', 'mean weighted b', 'SF cwf a', 'SF cwf b', 'SF cwf c']\n",
    "            pooled_results = {name:np.zeros(shape=(n_points, 2)) for name in names}\n",
    "            pooled_results['n'] = np.zeros(shape=(n_points), dtype='uint64')\n",
    "            results = {name:np.zeros(shape=(n_cores, 2)) for name in names}\n",
    "            \n",
    "            multi_proc_list = p.map(self.calculate_stats_looped_single_core, np.array_split(np.arange(52),4));\n",
    "            \n",
    "#             return multi_proc_list\n",
    "            \n",
    "        for key in names:\n",
    "            results[key] = np.concatenate([a[key] for a in multi_proc_list])\n",
    "            \n",
    "        for key in names:\n",
    "            if key != 'n':\n",
    "                pooled_mean = np.average(results[key][:,:,0], weights=results['n'], axis=0)\n",
    "                pooled_var  = np.average(results[key][:,:,1], weights=results['n'], axis=0) + np.average((results[key][:,:,0]-pooled_mean)**2, weights=results['n'], axis=0)\n",
    "\n",
    "                pooled_results[key][:,0] = pooled_mean\n",
    "                pooled_results[key][:,1] = pooled_var\n",
    "            else:\n",
    "                pooled_results[key] = results[key].sum(axis=0)\n",
    "        \n",
    "        self.pooled_stats = pooled_results\n",
    "        \n",
    "    def calculate_stats_looped_single_core(self, n_chunks_arr):\n",
    "        \"\"\"\n",
    "        Loop over dtdm files and calculate stats of each file. Append to dictionary.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_chunks : int\n",
    "            how many files to read in of files to read in.\n",
    "            maximum value: stars = 200/4 = 50, qsos = 52/4 = 13\n",
    "            \n",
    "        log_or_lin : str\n",
    "        \n",
    "        save : bool\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        results : dict of nd_arrays, shape (n_chunk, n_points)\n",
    "        \"\"\"\n",
    "        log_or_lin = 'log'\n",
    "        n_points=20 # number of points to plot\n",
    "        if log_or_lin.startswith('log'):\n",
    "            self.mjd_edges = np.logspace(0, 4.37247, n_points+1) # TODO add max t into argument\n",
    "        elif log_or_lin.startswith('lin'):\n",
    "            self.mjd_edges = np.linspace(0, 23576, n_points+1)\n",
    "            \n",
    "        self.mjd_centres = (self.mjd_edges[:-1] + self.mjd_edges[1:])/2\n",
    "\n",
    "        #hardcoding\n",
    "        n_chunks = 13\n",
    "\n",
    "#         names = ['n','SF 1', 'SF 2', 'SF 3', 'SF 4', 'SF weighted', 'SF corrected', 'SF corrected weighted', 'SF corrected weighted fixed', 'SF corrected weighted fixed 2', 'mean', 'mean weighted']\n",
    "        names = ['n', 'mean weighted a', 'mean weighted b', 'SF cwf a', 'SF cwf b', 'SF cwf c']\n",
    "        results = {name:np.zeros(shape=(n_chunks, n_points, 2)) for name in names} # 12/4 = 3, max is 52/4 = 13\n",
    "        results['n'] = np.zeros(shape=(n_chunks, n_points), dtype='uint64')\n",
    "           \n",
    "        for j in n_chunks_arr:\n",
    "            i = j % n_chunks\n",
    "#             self.read(i)\n",
    "            self.df = self.read_dtdm(self.fnames[j])\n",
    "            print('chunk: {}'.format(j))\n",
    "            for j, edges in enumerate(zip(self.mjd_edges[:-1], self.mjd_edges[1:])):\n",
    "                mjd_lower, mjd_upper = edges\n",
    "                boolean = (mjd_lower < self.df['dt']) & (self.df['dt']<mjd_upper)# & (self.df['dm2_de2']>0) # include last condition to remove negative SF values\n",
    "#                 print('number of points in {:.1f} < âˆ†t < {:.1f}: {}'.format(mjd_lower, mjd_upper, boolean.sum()))\n",
    "                subset = self.df[boolean]\n",
    "                subset.loc[(subset['dm2_de2']<0).values,'dm2_de2'] = 0 # Include for setting negative SF values to zero. Need .values for mask to prevent pandas warning\n",
    "                n = len(subset)\n",
    "                results['n'][i,j] = n\n",
    "                if n>0:\n",
    "#                     results['mean'][i,j, (0,1)] = subset['dm'].mean(), subset['dm'].std()\n",
    "\n",
    "#                     results['SF 1'][i,j,(0,1)] = (subset['dm']**2).mean(), (subset['de']**2).sum()/n\n",
    "#                     results['SF 2'][i,j,(0,1)] = (subset['dm']**2).mean(), (subset['dm']**2).var()\n",
    "#                     results['SF 3'][i,j,(0,1)] = (subset['dm']**2).mean(), 1/(subset['de']**-2).sum()\n",
    "\n",
    "#                     results['SF 4'][i,j,(0,1)] = (subset['dm']**2).mean(), (2*subset['de']**4).sum()/n\n",
    "\n",
    "#                     results['SF weighted'][i,j,(0,1)] = ( ((subset['dm']/subset['de'])**2) ).sum()/( (subset['de']**-2).sum() ), 1/(subset['de']**-2).sum()\n",
    "#                     results['SF corrected'][i,j,(0,1)] = subset['dm2_de2'].mean(), subset['dm2_de2'].var()\n",
    "#                     results['mean'][i,j,(0,1)] = subset['dm'].mean(), subset['dm'].std()\n",
    "                    weights = subset['de']**-2\n",
    "                    results['mean weighted a'][i,j,(0,1)] = np.average(subset['dm'], weights = weights), 1/weights.sum()\n",
    "                    results['mean weighted b'][i,j,(0,1)] = np.average(subset['dm'], weights = weights), subset['dm'].var()\n",
    "\n",
    "#                         results['SF corrected weighted'][i,j, group_idx, (0,1)] = ( subset['dm2_de2']/(subset['de']**2) ).sum()/( (subset['de']**-2).sum() ), 1/(subset['de']**-2).sum()\n",
    "                    weights = 0.5*subset['de']**-4\n",
    "                    results['SF cwf a'][i,j,(0,1)] = np.average(subset['dm2_de2'], weights = weights), 1/weights.sum()\n",
    "                    results['SF cwf b'][i,j,(0,1)] = np.average(subset['dm2_de2'], weights = weights), subset['dm2_de2'].var()\n",
    "                    results['SF cwf c'][i,j,(0,1)] = np.average(subset['dm2_de2'], weights = weights), (2*subset['de']**4).sum()/(n**2)\n",
    "\n",
    "                else:\n",
    "                    print('number of points in bin:', n)\n",
    "        return results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
