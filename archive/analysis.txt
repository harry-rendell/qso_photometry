read_in

summary

merge_with_catalogue

plot_series

group

plot_property_distributions

bounds

calc_dtdm

plot_sf_moments_pm

plot_sf_moments

plot_sf_ensemble







###############################BACK UP CALC DTDM

	def calc_dtdm(self, uids=None, n_bins_t = 1000, n_bins_m = 200, t_max=7600, t_spacing = 'log', m_spacing = 'log', read_in = False, key = None, ztf=False, rest_frame=True):
		"""
		Take batch of qsos from a MBH bin. Calculate all dtdm for these qsos.
		Section these values into 19 large Δt bins with logarithmic spacing.
		Within these large bins, bin Δt and Δm into 50 and 200 bins respectively.

		Parameters
		----------
		uids : array_like, list of qso uids whose lightcurves are to be used.
		n_bins_t  : int, total number of time bins.
		n_bins_m  : int, number of mag bins.
		t_max     : float, set this to largest ∆t in self.df (7600 for all surveys in obs frame, 3010 for all surveys in rest frame).
		t_spacing : str, ('log' or 'lin') for logarithmic and linear bin spacing respectively.
		m_spacing : str, ('log' or 'lin') for logarithmic and linear bin spacing respectively.
		read_in   : boolean, True to read in from disk, False to compute and return.
		key       : str, property from VAC.
		ztf       : boolean, True to use ztf data only.

		Returns
		-------
		dms_binned  : array_like, (19, n_bins_m)
		dts_binned  : array_like, (19, n_bins_t)
		t_bin_edges : array_like, (n_bins_t+1, )
		t_bin_chunk : array_like, ()
		t_bin_chunk_centres : array_like, (), centres of t bin chunk (NOT geometric average, could try this)
		m_bin_edges : array_like, ()
		m_bin_centres : array_like, ()
		t_dict      : dict,
		"""
		if m_spacing == 'log':
			def calc_m_edges(n_bins_m, steepness):
				start = np.log10(steepness)
				stop = np.log10(steepness+3)
				return np.concatenate((-np.logspace(start,stop,int(n_bins_m/2+1))[:0:-1]+steepness,np.logspace(start,stop,int(n_bins_m/2+1))-steepness))
			m_bin_edges = calc_m_edges(200,0.2)
		elif m_spacing == 'lin':
			m_bin_edges = np.linspace(-3,3,201)

		if t_spacing == 'log':
			def calc_t_bins(t_max, n_bins_t=19 , steepness=10):
				start = np.log10(steepness)
				stop = np.log10(steepness+t_max)
				return np.logspace(start,stop,n_bins_t+1)-steepness
			t_bin_chunk = calc_t_bins(t_max = t_max, steepness = 1000)
		elif t_spacing == 'lin':
			t_bin_chunk = np.linspace(0,t_max,20)

		t_bin_edges = np.linspace(0,t_max,(n_bins_t+1))
		t_dict = dict(enumerate(['{0:1.0f}<t<{1:1.0f}'.format(t_bin_chunk[i],t_bin_chunk[i+1]) for i in range(len(t_bin_chunk)-1)]))
		dts_binned = np.zeros((19,n_bins_t))
		dms_binned = np.zeros((19,n_bins_m))
		m_bin_centres = (m_bin_edges[1:] + m_bin_edges[:-1])/2
		t_bin_chunk_centres = (t_bin_chunk[1:] + t_bin_chunk[:-1])/2


		if read_in != False:
			if ztf == True:
				dms_binned = np.loadtxt(cfg.USER.W_DIR + 'analysis/dtdm/ztf/dms_binned_{}_{}.csv'.format(key,read_in), delimiter = ',')
			else:
				dms_binned = np.loadtxt(cfg.USER.W_DIR + 'analysis/qsos/computed/dtdm/{}/dms_binned_{}_{}.csv'.format(key,key,read_in), delimiter = ',')

	#		 dts_binned = np.loadtxt(cfg.USER.W_DIR + 'analysis/dtdm/dts_binned_{}_{}.csv'.format(key,read_in), delimiter = ',')

		elif read_in == False:
# 			z = self.df_grouped[self.df_grouped['mag_count']>2]['redshift'].loc[uids]
			z = self.redshifts.loc[uids]
			if rest_frame:
				sub_df = self.df[['mjd_rf','mag', 'catalogue']].loc[uids]
			else:
				sub_df = self.df[['mjd'   ,'mag', 'catalogue']].loc[uids]
			dtdms = [np.empty((0,2))]*19
			for uid,z in zip(uids,z.values):
				#maybe groupby then iterrows? faster?
				mjd_mag = sub_df.loc[uid].values

				# Rest frame - need to change time bins
				mjd_mag[:,0] /= (1+z)

				# dtdm defined as: ∆m = (m2 - m1), ∆t = (t2 - t1) where (t1, m1) is the first obs and (t2, m2) is the second obs.
				# Thus a negative ∆m corresponds to a brightening of the object
				dtdm = mjd_mag - mjd_mag[:,np.newaxis,:]
				dtdm = dtdm[np.triu_indices(len(mjd_mag),1)]
				dtdm = dtdm*np.sign(dtdm[:,0])[:,np.newaxis]
				idxs = np.digitize(dtdm[:,0], t_bin_chunk)-1
				for index in np.unique(idxs): #Can we vectorize this?
					dtdms[index] = np.append(dtdms[index],dtdm[(idxs == index),:],axis = 0)

			print('now binning')
			for i in range(19):
				print('dtdm counts in {}: {:,}'.format(t_dict[i],len(dtdms[i])))
				dts_binned[i] += np.histogram(dtdms[i][:,0], t_bin_edges)[0]
				dms_binned[i] += np.histogram(dtdms[i][:,1], m_bin_edges)[0]

		return dms_binned, dts_binned, t_bin_edges, t_bin_chunk, t_bin_chunk_centres, m_bin_edges, m_bin_centres, t_dict
